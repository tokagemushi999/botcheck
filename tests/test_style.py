# test_style.py - æ–‡ä½“åˆ†æã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
import pytest
from unittest.mock import Mock

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from analyzer.style import StyleAnalyzer

class TestStyleAnalyzer:
    
    def test_init(self):
        """StyleAnalyzeråˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        analyzer = StyleAnalyzer()
        assert analyzer is not None
    
    def test_formal_style_high_score(self, sample_messages_formal):
        """å®šå‹æ–‡ä½“ã¯é«˜ã‚¹ã‚³ã‚¢ï¼ˆBotç–‘ã„ï¼‰"""
        analyzer = StyleAnalyzer()
        score = analyzer.analyze_style(sample_messages_formal)
        
        # å®šå‹çš„ãªæ–‡ä½“ã¯é«˜ã‚¹ã‚³ã‚¢ï¼ˆ60ä»¥ä¸Šï¼‰
        assert score >= 60, f"Expected high score for formal style, got {score}"
    
    def test_varied_style_low_score(self, sample_messages_varied):
        """å¤šæ§˜ãªæ–‡ä½“ã¯ä½ã‚¹ã‚³ã‚¢ï¼ˆäººé–“ã‚‰ã—ã„ï¼‰"""
        analyzer = StyleAnalyzer()
        score = analyzer.analyze_style(sample_messages_varied)
        
        # å¤šæ§˜ãªæ–‡ä½“ã¯ä½ã‚¹ã‚³ã‚¢ï¼ˆ40ä»¥ä¸‹ï¼‰
        assert score <= 40, f"Expected low score for varied style, got {score}"
    
    def test_empty_messages(self):
        """ç©ºã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¯ä¸­ç«‹ã‚¹ã‚³ã‚¢"""
        analyzer = StyleAnalyzer()
        score = analyzer.analyze_style([])
        
        assert score == 50
    
    def test_calculate_ttr_diversity(self):
        """TTRï¼ˆèªå½™ã®å¤šæ§˜æ€§ï¼‰è¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
        analyzer = StyleAnalyzer()
        
        # ä½å¤šæ§˜æ€§ï¼ˆåŒã˜å˜èªã®ç¹°ã‚Šè¿”ã—ï¼‰
        repetitive_messages = []
        for i in range(5):
            msg = Mock()
            msg.content = "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚"
            repetitive_messages.append(msg)
        
        low_ttr = analyzer._calculate_ttr(repetitive_messages)
        
        # é«˜å¤šæ§˜æ€§ï¼ˆå¤šæ§˜ãªèªå½™ï¼‰
        diverse_messages = []
        diverse_texts = [
            "ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚",
            "æ˜¨æ—¥æ˜ ç”»ã‚’è¦‹ã¾ã—ãŸã€‚",
            "æ–°ã—ã„ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã‚’ç™ºè¦‹ã—ãŸã€‚",
            "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¯æ¥½ã—ã„ã€‚",
            "éŸ³æ¥½ã‚’è´ã„ã¦ã„ã¾ã™ã€‚"
        ]
        for text in diverse_texts:
            msg = Mock()
            msg.content = text
            diverse_messages.append(msg)
        
        high_ttr = analyzer._calculate_ttr(diverse_messages)
        
        assert high_ttr > low_ttr, "Diverse vocabulary should have higher TTR"
    
    def test_sentence_length_variance(self):
        """æ–‡é•·ã®ã°ã‚‰ã¤ãåˆ†æ"""
        analyzer = StyleAnalyzer()
        
        # ä¸€å®šã®æ–‡é•·ï¼ˆBotçš„ï¼‰
        uniform_messages = []
        for i in range(5):
            msg = Mock()
            msg.content = "ã“ã‚Œã¯ä¸€å®šã®é•·ã•ã®æ–‡ç« ã§ã™ã€‚"  # 15æ–‡å­—
            uniform_messages.append(msg)
        
        uniform_variance = analyzer._calculate_sentence_length_variance(uniform_messages)
        
        # ã°ã‚‰ã¤ãã®ã‚ã‚‹æ–‡é•·ï¼ˆäººé–“çš„ï¼‰
        varied_messages = []
        varied_texts = [
            "çŸ­ã„ã€‚",  # 3æ–‡å­—
            "ã“ã‚Œã¯ä¸­ç¨‹åº¦ã®é•·ã•ã®æ–‡ç« ã§ã™ã€‚",  # 16æ–‡å­—
            "ã“ã®æ–‡ç« ã¯ã‹ãªã‚Šé•·ãã¦ã€è©³ç´°ãªæƒ…å ±ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚ã¨ã¦ã‚‚å…·ä½“çš„ã§èª¬æ˜çš„ã§ã™ã€‚",  # 37æ–‡å­—
            "æ™®é€šã€‚",  # 3æ–‡å­—
            "ã¡ã‚‡ã†ã©ã„ã„é•·ã•ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã­ã€‚"  # 18æ–‡å­—
        ]
        
        for text in varied_texts:
            msg = Mock()
            msg.content = text
            varied_messages.append(msg)
        
        varied_variance = analyzer._calculate_sentence_length_variance(varied_messages)
        
        assert varied_variance > uniform_variance, "Varied sentence lengths should have higher variance"
    
    def test_detect_template_phrases(self):
        """å®šå‹ãƒ•ãƒ¬ãƒ¼ã‚ºã®æ¤œçŸ¥"""
        analyzer = StyleAnalyzer()
        
        template_messages = []
        template_phrases = [
            "ã”è³ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚",
            "ãŠå¿™ã—ã„ä¸­ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚",
            "ã”è³ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚",  # é‡è¤‡
            "æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚",
            "ãŠå¿™ã—ã„ä¸­ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚",  # é‡è¤‡
            "å¤±ç¤¼ã„ãŸã—ã¾ã™ã€‚"
        ]
        
        for phrase in template_phrases:
            msg = Mock()
            msg.content = phrase
            template_messages.append(msg)
        
        template_ratio = analyzer._calculate_template_phrase_ratio(template_messages)
        
        # å®šå‹ãƒ•ãƒ¬ãƒ¼ã‚ºãŒå¤šã„å ´åˆã¯æ¯”ç‡ãŒé«˜ã„
        assert template_ratio > 0.5, f"Expected high template ratio, got {template_ratio}"
    
    def test_emoji_usage_patterns(self):
        """çµµæ–‡å­—ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        analyzer = StyleAnalyzer()
        
        # Botçš„ï¼ˆçµµæ–‡å­—ãªã—ã€ã¾ãŸã¯ä¸€å®šãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        bot_messages = []
        for i in range(5):
            msg = Mock()
            msg.content = f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{i+1}ã§ã™ã€‚"  # çµµæ–‡å­—ãªã—
            bot_messages.append(msg)
        
        bot_emoji_score = analyzer._analyze_emoji_patterns(bot_messages)
        
        # äººé–“çš„ï¼ˆçµµæ–‡å­—ã‚’ãƒãƒ©ã‚¨ãƒ†ã‚£è±Šã‹ã«ä½¿ç”¨ï¼‰
        human_messages = []
        human_texts = [
            "ãŠã¯ã‚ˆã†ğŸ˜Š",
            "æ¥½ã—ã‹ã£ãŸï¼ğŸ˜„ğŸ‰",
            "ç–²ã‚ŒãŸ...ğŸ˜´",
            "ãã‚ŒãªğŸ’¯",
            "ã‚ã‚ŠãŒã¨ã†ğŸ™âœ¨"
        ]
        
        for text in human_texts:
            msg = Mock()
            msg.content = text
            human_messages.append(msg)
        
        human_emoji_score = analyzer._analyze_emoji_patterns(human_messages)
        
        # äººé–“ã®æ–¹ãŒçµµæ–‡å­—ä½¿ç”¨ã§ã‚ˆã‚Šä½ã‚¹ã‚³ã‚¢ï¼ˆè‡ªç„¶ï¼‰
        assert human_emoji_score < bot_emoji_score, "Humans should have more natural emoji patterns"
    
    def test_punctuation_patterns(self):
        """å¥èª­ç‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        analyzer = StyleAnalyzer()
        
        # Botçš„ï¼ˆå®Œç’§ãªå¥èª­ç‚¹ï¼‰
        bot_messages = []
        bot_texts = [
            "ã“ã‚“ã«ã¡ã¯ã€‚ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚",
            "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚",
            "å¤±ç¤¼ã„ãŸã—ã¾ã™ã€‚ã¾ãŸå¾Œã»ã©ã€‚"
        ]
        
        for text in bot_texts:
            msg = Mock()
            msg.content = text
            bot_messages.append(msg)
        
        # äººé–“çš„ï¼ˆå¥èª­ç‚¹ãŒä¸è¦å‰‡ï¼‰
        human_messages = []
        human_texts = [
            "ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã‚ã£ã¡ã‚ƒæš‘ã„ã­ã€œ",
            "ãã†ãã†ã€ãã‚Œã§çµå±€ã©ã†ãªã£ãŸã®ï¼Ÿï¼Ÿ",
            "äº†è§£ã§ã™ï¼ï¼ï¼ã‚ã‚ŠãŒã¨ã†â™ª"
        ]
        
        for text in human_texts:
            msg = Mock()
            msg.content = text
            human_messages.append(msg)
        
        bot_score = analyzer.analyze_style(bot_messages)
        human_score = analyzer.analyze_style(human_messages)
        
        # å®Œç’§ã™ãã‚‹å¥èª­ç‚¹ã¯Botç–‘ã„
        assert bot_score > human_score, "Perfect punctuation should raise bot suspicion"
    
    def test_polite_language_detection(self):
        """ä¸å¯§èªãƒ»æ•¬èªã®ä¸€è²«æ€§æ¤œçŸ¥"""
        analyzer = StyleAnalyzer()
        
        # ä¸€è²«ã—ã¦æ•¬èªï¼ˆBotç–‘ã„ï¼‰
        polite_messages = []
        polite_texts = [
            "ã„ã¤ã‚‚ãŠä¸–è©±ã«ãªã£ã¦ãŠã‚Šã¾ã™ã€‚",
            "ã”è³ªå•ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚",
            "æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚ç¢ºèªã„ãŸã—ã¾ã™ã€‚",
            "å¤±ç¤¼ã„ãŸã—ã¾ã™ã€‚"
        ]
        
        for text in polite_texts:
            msg = Mock()
            msg.content = text
            polite_messages.append(msg)
        
        # ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã¨æ•¬èªãŒæ··åœ¨ï¼ˆäººé–“çš„ï¼‰
        mixed_messages = []
        mixed_texts = [
            "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼",
            "äº†è§£ã€œ",
            "ãã†ã§ã™ã­ã€ç¢ºèªã—ã¾ã™ã­",
            "ãŠã¤ã‹ã‚Œï¼"
        ]
        
        for text in mixed_texts:
            msg = Mock()
            msg.content = text
            mixed_messages.append(msg)
        
        polite_score = analyzer.analyze_style(polite_messages)
        mixed_score = analyzer.analyze_style(mixed_messages)
        
        # ä¸€è²«ã—ãŸæ•¬èªã¯Botç–‘ã„
        assert polite_score > mixed_score, "Consistent polite language should raise bot suspicion"
    
    def test_japanese_specific_patterns(self):
        """æ—¥æœ¬èªç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        analyzer = StyleAnalyzer()
        
        # ã§ã™/ã¾ã™èª¿ãŒå®Œç’§ã™ãã‚‹ï¼ˆBotç–‘ã„ï¼‰
        formal_jp_messages = []
        formal_texts = [
            "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã§ã™ã€‚",
            "ç¢ºèªã„ãŸã—ã¾ã™ã€‚",
            "æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚",
            "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚"
        ]
        
        for text in formal_texts:
            msg = Mock()
            msg.content = text
            formal_jp_messages.append(msg)
        
        # è‡ªç„¶ãªæ—¥æœ¬èªï¼ˆã /ã§ã‚ã‚‹èª¿ã‚‚æ··åœ¨ï¼‰
        natural_jp_messages = []
        natural_texts = [
            "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã€‚",
            "ç¢ºèªã™ã‚‹ã­ï¼",
            "äº†è§£ã—ãŸ",
            "ã‚ã‚ŠãŒã¨ã†ã€œ"
        ]
        
        for text in natural_texts:
            msg = Mock()
            msg.content = text
            natural_jp_messages.append(msg)
        
        formal_score = analyzer.analyze_style(formal_jp_messages)
        natural_score = analyzer.analyze_style(natural_jp_messages)
        
        # å®Œç’§ãªæ•¬èªã¯Botç–‘ã„
        assert formal_score > natural_score, "Perfect formal Japanese should raise bot suspicion"